# Data Contract: ML Model Artifacts

This document specifies the required data files and their formats for the Culinary Compass inference system.

## Overview

The inference system expects **4 files** to be generated by the preprocessing pipeline. All files must be present for the system to function.

---

## Required Files

### 1. Recipe Database
**Path**: `data/processed/cleaned.json`  
**Format**: JSON array of recipe objects  
**Description**: Processed recipe data with cleaned ingredients

**Schema**:
```json
[
  {
    "name": "string (recipe title)",
    "ingredients": ["array", "of", "cleaned", "ingredient", "strings"],
    "directions": ["array", "of", "instruction", "strings"],
    "url": "string or null (source URL)"
  }
]
```

**Example**:
```json
[
  {
    "name": "Pasta Carbonara",
    "ingredients": ["pasta", "egg", "bacon", "parmesan cheese", "pepper"],
    "directions": [
      "Boil pasta.",
      "Fry bacon.",
      "Mix eggs and cheese.",
      "Combine everything with hot pasta."
    ],
    "url": "http://example.com/carbonara"
  }
]
```

**Export Code**:
```python
import json

# Assuming recipes_df has columns: recipe_title, clean_ingredients_norm, directions, url
final_recipes = []
for _, row in recipes_df.iterrows():
    final_recipes.append({
        "name": row["recipe_title"],
        "ingredients": row["clean_ingredients_norm"],  # Already cleaned/normalized
        "directions": row["directions"],
        "url": row.get("url", None)
    })

with open("../data/processed/cleaned.json", "w") as f:
    json.dump(final_recipes, f, indent=2)
```

---

### 2. TF-IDF Vectorizer
**Path**: `data/models/tfidf_vectorizer.pkl`  
**Format**: Pickled scikit-learn TfidfVectorizer object  
**Description**: Trained TF-IDF vectorizer for keyword-based matching

**Export Code**:
```python
import pickle
import os

os.makedirs("../data/models", exist_ok=True)

with open("../data/models/tfidf_vectorizer.pkl", "wb") as f:
    pickle.dump(vectorizer, f)
```

---

### 3. TF-IDF Matrix
**Path**: `data/models/tfidf_matrix.npz`  
**Format**: Compressed scipy sparse matrix (CSR format)  
**Description**: TF-IDF vectors for all recipes (NOT the similarity matrix)

**Important**: This should be the **TF-IDF feature matrix** (the `X` variable after `vectorizer.fit_transform()`), NOT the pre-computed similarity matrix.

**Export Code**:
```python
import scipy.sparse

# X is the result of vectorizer.fit_transform(documents)
scipy.sparse.save_npz("../data/models/tfidf_matrix.npz", X)
```

---

### 4. Recipe Embeddings
**Path**: `data/models/embeddings.npy`  
**Format**: NumPy array of shape (n_recipes, embedding_dim)  
**Description**: Semantic embeddings for all recipes (typically using SentenceTransformer)

**Export Code**:
```python
import numpy as np

# embeddings from SentenceTransformer model
np.save("../data/models/embeddings.npy", embeddings)
```

---

## Directory Structure

After preprocessing, the directory structure should look like:

```
culinary_compass/
├── data/
│   ├── processed/
│   │   └── cleaned.json          ← Recipe database
│   └── models/
│       ├── tfidf_vectorizer.pkl  ← TF-IDF vectorizer
│       ├── tfidf_matrix.npz      ← TF-IDF matrix
│       └── embeddings.npy        ← Semantic embeddings
```

---

## Validation Checklist

Before delivering artifacts, verify:

- [ ] All 4 files exist in the correct locations
- [ ] `cleaned.json` is valid JSON and contains an array
- [ ] Each recipe has `name`, `ingredients`, `directions` fields
- [ ] `ingredients` is an array of strings (not nested arrays)
- [ ] `tfidf_matrix.npz` shape matches number of recipes in `cleaned.json`
- [ ] `embeddings.npy` shape matches number of recipes in `cleaned.json`
- [ ] Files are in the correct directories (`data/processed/` vs `data/models/`)

---

## Common Mistakes to Avoid

❌ **Saving similarity matrix instead of TF-IDF matrix**
- The inference needs the raw TF-IDF vectors (`X`), not pre-computed similarities

❌ **Wrong file names**
- Must be exactly `embeddings.npy`, not `recipe_embeddings.npy`

❌ **Nested ingredient lists**
- `ingredients` should be `["a", "b", "c"]`, not `[["a"], ["b"], ["c"]]`

❌ **Wrong directory**
- Models go in `data/models/`, recipes in `data/processed/`

---

## Testing After Export

You can verify the files are correct by running:

```python
# Test 1: Load and count recipes
import json
with open("../data/processed/cleaned.json") as f:
    recipes = json.load(f)
print(f"✓ Loaded {len(recipes)} recipes")

# Test 2: Check TF-IDF matrix shape
import scipy.sparse
tfidf_matrix = scipy.sparse.load_npz("../data/models/tfidf_matrix.npz")
print(f"✓ TF-IDF matrix shape: {tfidf_matrix.shape}")

# Test 3: Check embeddings shape
import numpy as np
embeddings = np.load("../data/models/embeddings.npy")
print(f"✓ Embeddings shape: {embeddings.shape}")

# Test 4: Verify shapes match
assert tfidf_matrix.shape[0] == len(recipes), "TF-IDF matrix rows != recipe count"
assert embeddings.shape[0] == len(recipes), "Embeddings rows != recipe count"
print("✓ All shapes match!")
```
